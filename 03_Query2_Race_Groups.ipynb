{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360ce00e-4469-43b7-8bb8-a535a819264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>740</td><td>application_1765289937462_0733</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0733/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0733_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783e85435c2f42fea6ca3a2203cace52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d06e6bf3a814d3280bfce06e6627d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, count, year \n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LA_Crime_Query_X\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "# Load Clean Data \n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98311f8-60fc-4465-b759-049eb2d1e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15387d6a02443e1bb7b3ef942fb4004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Clean Data...\n",
      "Data Loaded. Rows: 3134980\n",
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA: integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- DATE_OCC: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Vict_Age: integer (nullable = true)\n",
      " |-- is_severe: boolean (nullable = true)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#  Ξεκινάμε το Spark\n",
    "spark = SparkSession.builder.appName(\"Query_Notebook\").getOrCreate()\n",
    "\n",
    "#  Ορίζουμε το Path \n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "# 3. Φορτώνουμε τα καθαρά δεδομένα\n",
    "\n",
    "print(\"Loading Clean Data...\")\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")\n",
    "\n",
    "# 4. Τυπώνουμε για επιβεβαίωση\n",
    "print(f\"Data Loaded. Rows: {df_crime.count()}\")\n",
    "df_crime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5274d811-8214-49dc-ba88-53d1c7fa9aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62289c45962346e884760b7c42efaf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "invalid syntax (<stdin>, line 1)\n",
      "  File \"<stdin>\", line 1\n",
      "    Query 2 - ??? ????, ?? ??????? ?? 3 ???????? groups ?? ?? ??????????? ?????? ??????????????? ?????????? ??? LA.\n",
      "          ^\n",
      "SyntaxError: invalid syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Query 2 - Ανα έτος, να βρεθούν τα 3 φυλετικά groups με τα περισσότερα θυματα καταγεγραμμένων εγκλημάτων στο LA.\n",
    "Τα αποτελέσματα να εμφανιστούν με φθίνουσα σειρά αριθμού θυμάτων ανά φυλετικό γκρουπ, να υπολογιστεί και να εμφανιστεί \n",
    "επίσης το ποσοστό επί του συνολικού αριθμού θυμάτων ανά περίπτωση. \n",
    "Να υλοποιηθεί το query 2 χρησιμοποιώντας dataframe API και SQL APIs, με 4 executors όπως παραπάνω. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14703901-2ff6-42f3-b6fd-5117ced5b209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c45d11951447a395fb9ddac4bab428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "Crime Data Rows: 3138128\n",
      "Data loaded successfully."
     ]
    }
   ],
   "source": [
    "# φορτώνουμε τα καθορισμένα δεδομένα και τον πίνακα φυλών από εκεί που τα αποθηκεύσαμε (processed_data)\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, year, count, sum as _sum, desc, rank, round\n",
    "\n",
    "# Αρχικοποίηση Spark\n",
    "spark = SparkSession.builder.appName(\"LA_Crime_Query2\").getOrCreate()\n",
    "\n",
    "# Path δεδομένων \n",
    "\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "print(\"--- Loading Data ---\")\n",
    "# Φόρτωση Clean Crime Data\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_raw.parquet\")\n",
    "\n",
    "#  Φόρτωση Race Codes\n",
    "df_race_codes = spark.read.parquet(f\"{DATA_PATH}/race_codes.parquet\")\n",
    "\n",
    "print(f\"Crime Data Rows: {df_crime.count()}\")\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfa92e8-6542-422f-9ec1-d8e7e448ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ee830591fc4cdf8acb2e8c0b974254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading Raw Data...\n",
      "2. Parsing Dates & Extracting Year (Python Method)...\n",
      "3. Validating Year Column...\n",
      "+--------------------+----+\n",
      "|            DATE OCC|Year|\n",
      "+--------------------+----+\n",
      "|2024 Feb 23 12:00...|2024|\n",
      "|2024 Jan 29 12:00...|2024|\n",
      "|2024 Jan 07 12:00...|2024|\n",
      "|2024 Jul 04 12:00...|2024|\n",
      "|2024 Sep 11 12:00...|2024|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "4. SAVING crime_data_clean.parquet ...\n",
      "SUCCESS: crime_data_clean.parquet created successfully!"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Preprocessing_Fix\").getOrCreate()\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "print(\"1. Reading Raw Data...\")\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_raw.parquet\")\n",
    "\n",
    "print(\"2. Parsing Dates & Extracting Year (Python Method)...\")\n",
    "\n",
    "# Schema για την επιστροφή της UDF (Ημερομηνία string + Έτος int)\n",
    "output_schema = StructType([\n",
    "    StructField(\"iso_string\", StringType(), True),\n",
    "    StructField(\"year_val\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Η συνάρτηση που φτιάχνει τη χρονιά\n",
    "def parse_date_and_year(date_str):\n",
    "    if not date_str: return (None, None)\n",
    "    formats = [\"%Y %b %d %I:%M:%S %p\", \"%m/%d/%Y %I:%M:%S %p\", \"%m/%d/%Y\"]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str, fmt)\n",
    "            return (dt.strftime(\"%Y-%m-%d %H:%M:%S\"), dt.year)\n",
    "        except ValueError: continue\n",
    "    return (None, None)\n",
    "parse_udf = udf(parse_date_and_year, output_schema)\n",
    "\n",
    "# Εφαρμογή της λογικής\n",
    "df_temp = df_crime \\\n",
    "    .withColumn(\"parsed_occ\", parse_udf(col(\"DATE OCC\")))\n",
    "\n",
    "df_clean = df_temp \\\n",
    "    .withColumn(\"DATE_OCC\", to_timestamp(col(\"parsed_occ.iso_string\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withColumn(\"Year\", col(\"parsed_occ.year_val\")) \\\n",
    "    .drop(\"parsed_occ\") \\\n",
    "    .withColumn(\"Vict_Age\", col(\"Vict Age\").cast(\"integer\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\"))\n",
    "\n",
    "# Φίλτρα (Null Island & Severe Flag)\n",
    "df_clean = df_clean.filter((col(\"LAT\") != 0) | (col(\"LON\") != 0))\n",
    "df_clean = df_clean.withColumn(\"is_severe\", col(\"Crm Cd Desc\").contains(\"AGGRAVATED ASSAULT\"))\n",
    "\n",
    "print(\"3. Validating Year Column...\")\n",
    "# Έλεγχος ότι η στήλη Year υπάρχει και έχει δεδομένα\n",
    "df_clean.select(\"DATE OCC\", \"Year\").show(5)\n",
    "\n",
    "print(\"4. SAVING crime_data_clean.parquet ...\")\n",
    "\n",
    "df_clean.write.mode(\"overwrite\").parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")\n",
    "\n",
    "print(\"SUCCESS: crime_data_clean.parquet created successfully!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102963ef-f488-480c-8d9e-52bd0fcf0330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937e0949da0142718fc8ce30c8e7bef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Prepared Data ---\n",
      "Columns in crime dataset: ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes', 'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc', 'Weapon Used Cd', 'Weapon Desc', 'Status', 'Status Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'LOCATION', 'Cross Street', 'LAT', 'LON', 'DATE_OCC', 'Year', 'Vict_Age', 'is_severe']\n",
      "Dataset Loaded. Rows: 2792396\n",
      "+----+--------------------+\n",
      "|Year|      Victim_Descent|\n",
      "+----+--------------------+\n",
      "|2020|Hispanic/Latin/Me...|\n",
      "|2020|               Black|\n",
      "|2020|               Other|\n",
      "|2020|         Other Asian|\n",
      "|2020|             Unknown|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Loading Prepared Data ---\")\n",
    "\n",
    "\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")\n",
    "df_race_codes = spark.read.parquet(f\"{DATA_PATH}/race_codes.parquet\")\n",
    "\n",
    "# Debug: Επιβεβαίωση ότι υπάρχει η στήλη Year\n",
    "print(\"Columns in crime dataset:\", df_crime.columns)\n",
    "\n",
    "# Join Logic\n",
    "actual_col_1 = df_race_codes.columns[0]\n",
    "actual_col_2 = df_race_codes.columns[1]\n",
    "df_race_codes_fixed = df_race_codes \\\n",
    "    .withColumnRenamed(actual_col_1, \"Code\") \\\n",
    "    .withColumnRenamed(actual_col_2, \"Description\")\n",
    "\n",
    "df_joined = df_crime.join(\n",
    "    df_race_codes_fixed, \n",
    "    df_crime[\"Vict Descent\"] == df_race_codes_fixed[\"Code\"], \n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"Year\"),  \n",
    "    col(\"Description\").alias(\"Victim_Descent\") \n",
    ")\n",
    "\n",
    "df_joined.cache()\n",
    "print(f\"Dataset Loaded. Rows: {df_joined.count()}\")\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e9d2ea-b876-49ee-b4c3-fcf3f8639bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24b04b80d944bc7a3f79bdc6209f5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark_query(name, func):\n",
    "    # Force garbage collection \n",
    "    spark.catalog.clearCache() \n",
    "    # Ξανα-κάνουμε cache μόνο το df_joined που μας ενδιαφέρει\n",
    "    df_joined.cache()\n",
    "    df_joined.count() \n",
    "    \n",
    "    print(f\"Starting execution for: {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Εκτέλεση Query\n",
    "    result_df = func()\n",
    "    \n",
    "    \n",
    "    # Χρησιμοποιούμε .show() για να δούμε και τα αποτελέσματα όπως ζητάει η εκφώνηση\n",
    "    result_df.show(5, truncate=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"--> Time taken for {name}: {duration:.4f} seconds\\n\")\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd890d2c-f746-473d-8adf-4c8515f704f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1dbd078a0a47ddb6359b2c1ddfc9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution for: Query 2 (DataFrame API)...\n",
      "+----+----------------------+-----+-----+\n",
      "|Year|Victim_Descent        |#    |%    |\n",
      "+----+----------------------+-----+-----+\n",
      "|2025|Hispanic/Latin/Mexican|34   |40.48|\n",
      "|2025|Unknown               |24   |28.57|\n",
      "|2025|White                 |13   |15.48|\n",
      "|2024|Hispanic/Latin/Mexican|28576|29.05|\n",
      "|2024|White                 |22958|23.34|\n",
      "+----+----------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "--> Time taken for Query 2 (DataFrame API): 2.2156 seconds"
     ]
    }
   ],
   "source": [
    "def query2_dataframe():\n",
    "    #  Group by Year & Descent\n",
    "    df_grouped = df_joined.groupBy(\"Year\", \"Victim_Descent\").agg(count(\"*\").alias(\"count\"))\n",
    "    \n",
    "    #  Window Functions\n",
    "    window_total = Window.partitionBy(\"Year\")\n",
    "    window_rank = Window.partitionBy(\"Year\").orderBy(col(\"count\").desc())\n",
    "    \n",
    "    # Calcs\n",
    "    df_final = df_grouped \\\n",
    "        .withColumn(\"total_year\", _sum(\"count\").over(window_total)) \\\n",
    "        .withColumn(\"percentage\", round((col(\"count\") / col(\"total_year\")) * 100, 2)) \\\n",
    "        .withColumn(\"rank\", rank().over(window_rank)) \\\n",
    "        .filter(col(\"rank\") <= 3) \\\n",
    "        .select(\"Year\", \"Victim_Descent\", col(\"count\").alias(\"#\"), col(\"percentage\").alias(\"%\")) \\\n",
    "        .orderBy(col(\"Year\").desc(), col(\"#\").desc())\n",
    "        \n",
    "    return df_final\n",
    "\n",
    "time_df = benchmark_query(\"Query 2 (DataFrame API)\", query2_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867959d7-5890-4a3a-a728-0519eaf8d4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2adcff6ec144149006ff5388b3d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data for SQL ---\n",
      "Views created: 'crime_table' and 'race_table' are ready for SQL."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#  Setup Spark (4 executors, 1 core, 2GB)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LA_Crime_Query2_SQL\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "# Load Data\n",
    "print(\"--- Loading Data for SQL ---\")\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")\n",
    "df_race = spark.read.parquet(f\"{DATA_PATH}/race_codes.parquet\")\n",
    "\n",
    "# 3. Fix Race Codes Column Names (Για να μην έχουμε θέμα στην SQL)\n",
    "# Μετονομάζουμε τις στήλες σε \"Code\" και \"Description\" για σιγουριά\n",
    "cols = df_race.columns\n",
    "df_race_fixed = df_race.withColumnRenamed(cols[0], \"Code\").withColumnRenamed(cols[1], \"Description\")\n",
    "\n",
    "# 4. Register Temp Views (ΕΔΩ ΕΙΝΑΙ ΤΟ ΜΥΣΤΙΚΟ)\n",
    "# Τώρα η SQL μπορεί να βλέπει τους πίνακες \"crime_table\" και \"race_table\"\n",
    "df_crime.createOrReplaceTempView(\"crime_table\")\n",
    "df_race_fixed.createOrReplaceTempView(\"race_table\")\n",
    "\n",
    "print(\"Views created: 'crime_table' and 'race_table' are ready for SQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e38964-28d3-421c-83d5-2bf1f38d8287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d124176ef54b1ab2b4b1fd82370ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def query2_sql_implementation():\n",
    "    # Γράφουμε το SQL Query σε string\n",
    "    sql_string = \"\"\"\n",
    "    WITH JoinedData AS (\n",
    "        -- 1. Join για να πάρουμε την περιγραφή της φυλής\n",
    "        SELECT \n",
    "            c.Year, \n",
    "            r.Description as Victim_Descent\n",
    "        FROM crime_table c\n",
    "        JOIN race_table r ON c.`Vict Descent` = r.Code\n",
    "    ),\n",
    "    GroupedData AS (\n",
    "        -- 2. Group by Year & Descent -> Count\n",
    "        SELECT \n",
    "            Year, \n",
    "            Victim_Descent, \n",
    "            COUNT(*) as count\n",
    "        FROM JoinedData\n",
    "        WHERE Year IS NOT NULL\n",
    "        GROUP BY Year, Victim_Descent\n",
    "    ),\n",
    "    WindowedData AS (\n",
    "        -- 3. Window Functions για Total και Rank\n",
    "        SELECT \n",
    "            Year, \n",
    "            Victim_Descent, \n",
    "            count,\n",
    "            SUM(count) OVER (PARTITION BY Year) as total_year,\n",
    "            RANK() OVER (PARTITION BY Year ORDER BY count DESC) as rn\n",
    "        FROM GroupedData\n",
    "    )\n",
    "    -- 4. Final Select: Top 3 & Percentage Calculation\n",
    "    SELECT \n",
    "        Year, \n",
    "        Victim_Descent, \n",
    "        count as `#`, \n",
    "        ROUND((count / total_year) * 100, 2) as `%`\n",
    "    FROM WindowedData\n",
    "    WHERE rn <= 3\n",
    "    ORDER BY Year DESC, count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Εκτέλεση του SQL\n",
    "    return spark.sql(sql_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e802198-60ba-4864-b02c-816c989bab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b26aef2ee482b9c0d1306f5068370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution for: Query 2 (SQL API)...\n",
      "+----+----------------------+-----+-----+\n",
      "|Year|Victim_Descent        |#    |%    |\n",
      "+----+----------------------+-----+-----+\n",
      "|2025|Hispanic/Latin/Mexican|34   |40.48|\n",
      "|2025|Unknown               |24   |28.57|\n",
      "|2025|White                 |13   |15.48|\n",
      "|2024|Hispanic/Latin/Mexican|28576|29.05|\n",
      "|2024|White                 |22958|23.34|\n",
      "|2024|Unknown               |19984|20.32|\n",
      "|2023|Hispanic/Latin/Mexican|69400|34.55|\n",
      "|2023|White                 |44613|22.21|\n",
      "|2023|Black                 |30504|15.19|\n",
      "|2022|Hispanic/Latin/Mexican|73111|35.64|\n",
      "+----+----------------------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "--> Time taken for Query 2 (SQL API): 1.6039 seconds"
     ]
    }
   ],
   "source": [
    "# Συνάρτηση μέτρησης (ίδια με πριν)\n",
    "def benchmark_query(name, func):\n",
    "    spark.catalog.clearCache()\n",
    "    # Κάνουμε cache τους αρχικούς πίνακες για να μετρήσουμε μόνο το SQL execution\n",
    "    spark.table(\"crime_table\").cache()\n",
    "    spark.table(\"crime_table\").count()\n",
    "    \n",
    "    print(f\"Starting execution for: {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result_df = func()\n",
    "    result_df.show(10, truncate=False) # Δείχνουμε τις πρώτες 10 γραμμές\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"--> Time taken for {name}: {duration:.4f} seconds\\n\")\n",
    "    return duration\n",
    "\n",
    "# Εκτέλεση\n",
    "time_sql = benchmark_query(\"Query 2 (SQL API)\", query2_sql_implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2bc50-adb3-4416-b7dd-ac32440c6c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
