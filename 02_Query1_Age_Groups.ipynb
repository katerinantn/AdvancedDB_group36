{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaf469f-21ee-4a21-8af9-45669afc100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>739</td><td>application_1765289937462_0732</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0732/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0732_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ce86d60d4e47a38ba459f222d47e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0e7aa847664e6b859fcb27d3e6b79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, count, year # κτλ...\n",
    "\n",
    "# 1. Start Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LA_Crime_Query_X\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Define Path\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "# 3. Load Clean Data (Αυτό που φτιάξαμε στο Notebook 02)\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ee33b5-6a91-4285-8faa-0a27bab5d4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd8672eb1564463810f28577e6c79c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Clean Data...\n",
      "Data Loaded. Rows: 3134980\n",
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA: integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- DATE_OCC: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Vict_Age: integer (nullable = true)\n",
      " |-- is_severe: boolean (nullable = true)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1. Ξεκινάμε το Spark\n",
    "spark = SparkSession.builder.appName(\"Query_Notebook\").getOrCreate()\n",
    "\n",
    "# 2. Ορίζουμε το Path (το δικό σου group path)\n",
    "DATA_PATH = \"s3a://groups-bucket-dblab-905418150721/group36/processed_data\"\n",
    "\n",
    "# 3. Φορτώνουμε τα ΚΑΘΑΡΑ δεδομένα (όχι τα raw)\n",
    "# ΠΡΟΣΟΧΗ: Στο Notebook 1 το έλεγες 'df_crime_total'. \n",
    "# Εδώ θα το φορτώσουμε ως 'df_crime' (είναι πιο σύντομο).\n",
    "print(\"Loading Clean Data...\")\n",
    "df_crime = spark.read.parquet(f\"{DATA_PATH}/crime_data_clean.parquet\")\n",
    "\n",
    "# 4. Τυπώνουμε για επιβεβαίωση\n",
    "print(f\"Data Loaded. Rows: {df_crime.count()}\")\n",
    "df_crime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c28408d-7c1e-4436-bfe5-bf5117a22631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44464a9119e94f96a60fd3118d4fc03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "invalid syntax (<stdin>, line 1)\n",
      "  File \"<stdin>\", line 1\n",
      "    QUERY 1 - ?? ??????????????, ?? ???????? ?????, ?? ????????? ?????? ??? ??????? ?? ??????????? ??? ????-\n",
      "          ^\n",
      "SyntaxError: invalid syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QUERY 1 - Να ταξινομημηθούν, σε φθίνουσα σειρά, οι ηλικιακές ομάδες των θυμάτων σε περιστατικά που περι-\n",
    "λαμβάνουν οποιαδήποτε μορφή “βαριάς σωματικής βλάβης”. Θεωρούμε 4 ηλικιακές ομάδες:\n",
    "    1. Παιδιά <18 ετών\n",
    "    2. Νεαροί ενήλικοι 18-24 ετών\n",
    "    3.Ενήλικοι 25-64 ετών\n",
    "    4.Ηλικιωμένοι >64 ετών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f356710-8e16-498b-9e9a-48d53f929612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b300b403af334d6d9d8a7770ca9a810c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances of Aggravated Assault: 177381\n",
      "\n",
      "Instances of Aggravated Assault:\n",
      "+----------------------------------------------+--------+\n",
      "|Crm Cd Desc                                   |Vict Age|\n",
      "+----------------------------------------------+--------+\n",
      "|ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT|50      |\n",
      "|ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT|56      |\n",
      "|ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT|39      |\n",
      "|ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT|58      |\n",
      "|INTIMATE PARTNER - AGGRAVATED ASSAULT         |38      |\n",
      "+----------------------------------------------+--------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "\n",
    "#Αναζήτηση για Aggravated Assault στη στήλη Crm Cd Desc\n",
    "df_agg_assault = df_crime.filter(\n",
    "    upper(col(\"Crm Cd Desc\")).contains(\"AGGRAVATED ASSAULT\")\n",
    ")\n",
    "\n",
    "count_agg_assault = df_agg_assault.count()\n",
    "print(f\"instances of Aggravated Assault: {count_agg_assault}\")\n",
    "\n",
    "#Αν βρέθηκαν αποτελέσματα, εμφάνιση παραδειγμάτων\n",
    "if count_agg_assault > 0:\n",
    "    print(\"\\nInstances of Aggravated Assault:\")\n",
    "    df_agg_assault.select(\"Crm Cd Desc\", \"Vict Age\").show(5, truncate=False)\n",
    "else:\n",
    "    print(\"\\nno instances of Aggravated Assault found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0af38f7-f673-4047-ba49-2f39fe016082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db72ad3f978d4660a35a6f57356ac691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original aggravated assault count: 177381\n",
      "\n",
      "Checking Vict Age column type:\n",
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA: integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- DATE_OCC: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Vict_Age: integer (nullable = true)\n",
      " |-- is_severe: boolean (nullable = true)\n",
      "\n",
      "\n",
      "Sample Vict Age values (raw):\n",
      "+--------+\n",
      "|Vict Age|\n",
      "+--------+\n",
      "|      65|\n",
      "|      81|\n",
      "|      76|\n",
      "|      12|\n",
      "|       6|\n",
      "|       3|\n",
      "|      92|\n",
      "|      64|\n",
      "|      37|\n",
      "|      61|\n",
      "+--------+\n",
      "\n",
      "After basic filtering: 172276\n",
      "After age range filter (1-120): 172271"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "print(f\"Original aggravated assault count: {df_agg_assault.count()}\")\n",
    "\n",
    "# First, let's check the data type of Vict Age\n",
    "print(\"\\nChecking Vict Age column type:\")\n",
    "df_agg_assault.printSchema()\n",
    "\n",
    "# Show some raw values to see what we have\n",
    "print(\"\\nSample Vict Age values (raw):\")\n",
    "df_agg_assault.select(\"Vict Age\").distinct().limit(10).show()\n",
    "\n",
    "# Better approach: Handle nulls and invalid numbers\n",
    "df_agg_clean = df_agg_assault.filter(\n",
    "    col(\"Vict Age\").isNotNull()\n",
    ").filter(\n",
    "    # Cast to string first for comparison, then back to int\n",
    "    col(\"Vict Age\").cast(\"string\") != \"0\"\n",
    ").filter(\n",
    "    col(\"Vict Age\").cast(\"string\") != \"\"\n",
    ")\n",
    "\n",
    "print(f\"After basic filtering: {df_agg_clean.count()}\")\n",
    "\n",
    "# Now convert to integer\n",
    "df_agg_clean = df_agg_clean.withColumn(\n",
    "    \"Vict_Age_Int\",\n",
    "    col(\"Vict Age\").cast(IntegerType())\n",
    ")\n",
    "\n",
    "# Filter for reasonable age range\n",
    "df_agg_clean = df_agg_clean.filter(\n",
    "    (col(\"Vict_Age_Int\") > 0) & \n",
    "    (col(\"Vict_Age_Int\") <= 120)\n",
    ")\n",
    "\n",
    "print(f\"After age range filter (1-120): {df_agg_clean.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469dc2ed-295d-4e03-b030-e2424a6e60bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14e1a66efd0465bb9a15acfd2d285fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Grouping victims into age categories\n",
      "Sample of age group assignment:\n",
      "+------------+--------------------+\n",
      "|Vict_Age_Int|Age_Group           |\n",
      "+------------+--------------------+\n",
      "|50          |Adults (25-64)      |\n",
      "|56          |Adults (25-64)      |\n",
      "|39          |Adults (25-64)      |\n",
      "|58          |Adults (25-64)      |\n",
      "|38          |Adults (25-64)      |\n",
      "|38          |Adults (25-64)      |\n",
      "|46          |Adults (25-64)      |\n",
      "|23          |Young Adults (18-24)|\n",
      "|23          |Young Adults (18-24)|\n",
      "|36          |Adults (25-64)      |\n",
      "+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Total victims analyzed: 172271\n",
      "Victim count by age group (descending order):\n",
      "+--------------------+------------+\n",
      "|Age_Group           |Victim_Count|\n",
      "+--------------------+------------+\n",
      "|Adults (25-64)      |121620      |\n",
      "|Young Adults (18-24)|33741       |\n",
      "|Children (<18)      |10899       |\n",
      "|Elderly (>64)       |6011        |\n",
      "+--------------------+------------+\n",
      "\n",
      "\n",
      "Final result with percentages:\n",
      "+--------------------+------------+----------+\n",
      "|Age_Group           |Victim_Count|Percentage|\n",
      "+--------------------+------------+----------+\n",
      "|Adults (25-64)      |121620      |70.60     |\n",
      "|Young Adults (18-24)|33741       |19.59     |\n",
      "|Children (<18)      |10899       |6.33      |\n",
      "|Elderly (>64)       |6011        |3.49      |\n",
      "+--------------------+------------+----------+\n",
      "\n",
      "\n",
      "Distribution summary:\n",
      "  Adults (25-64): 121620 victims (70.60%)\n",
      "  Young Adults (18-24): 33741 victims (19.59%)\n",
      "  Children (<18): 10899 victims (6.33%)\n",
      "  Elderly (>64): 6011 victims (3.49%)\n",
      "\n",
      "Step 4 completed.\n",
      "--- Total Execution Time: 4.54 seconds ---"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from pyspark.sql.functions import col, when, count, desc\n",
    "\n",
    "# 1. START TIMER\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Step 4: Grouping victims into age categories\")\n",
    "\n",
    "# (Assuming df_agg_clean exists from a previous step)\n",
    "\n",
    "# Create age groups based on the specified ranges\n",
    "df_age_groups = df_agg_clean.withColumn(\n",
    "    \"Age_Group\",\n",
    "    when(col(\"Vict_Age_Int\") < 18, \"Children (<18)\")\n",
    "    .when((col(\"Vict_Age_Int\") >= 18) & (col(\"Vict_Age_Int\") <= 24), \"Young Adults (18-24)\")\n",
    "    .when((col(\"Vict_Age_Int\") >= 25) & (col(\"Vict_Age_Int\") <= 64), \"Adults (25-64)\")\n",
    "    .when(col(\"Vict_Age_Int\") > 64, \"Elderly (>64)\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")\n",
    "\n",
    "print(\"Sample of age group assignment:\")\n",
    "df_age_groups.select(\"Vict_Age_Int\", \"Age_Group\").show(10, truncate=False)\n",
    "\n",
    "# Group by age group and count\n",
    "df_age_counts = df_age_groups.groupBy(\"Age_Group\") \\\n",
    "    .agg(count(\"*\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\"))\n",
    "\n",
    "# Cache this count so we don't recalculate it twice\n",
    "total_victims = df_age_groups.count()\n",
    "\n",
    "print(f\"\\nTotal victims analyzed: {total_victims}\")\n",
    "print(\"Victim count by age group (descending order):\")\n",
    "df_age_counts.show(truncate=False)\n",
    "# Calculate percentage for each group\n",
    "df_final_result = df_age_counts.withColumn(\n",
    "    \"Percentage\",\n",
    "    (col(\"Victim_Count\") / total_victims * 100).cast(\"decimal(5,2)\")\n",
    ")\n",
    "\n",
    "print(\"\\nFinal result with percentages:\")\n",
    "df_final_result.show(truncate=False)\n",
    "\n",
    "# Also show the distribution visually\n",
    "print(\"\\nDistribution summary:\")\n",
    "for row in df_final_result.collect():\n",
    "    group = row[\"Age_Group\"]\n",
    "    # FIX: Renamed variable from 'count' to 'v_count' to avoid overwriting the PySpark function\n",
    "    v_count = row[\"Victim_Count\"] \n",
    "    perc = row[\"Percentage\"]\n",
    "    print(f\"  {group}: {v_count} victims ({perc}%)\")\n",
    "\n",
    "print(\"\\nStep 4 completed.\")\n",
    "\n",
    "# 2. END TIMER AND PRINT\n",
    "print(f\"--- Total Execution Time: {time.time() - start_time:.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec875a5d-cfc5-4ccb-9e42-6aaf8daf4fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a05df7bbdf408b820138f65e39a081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: DataFrame API WITH UDF\n",
      "Starting execution time measurement...\n",
      "\n",
      "UDF Results:\n",
      "+--------------------+------------+----------+\n",
      "|Age_Group_UDF       |Victim_Count|Percentage|\n",
      "+--------------------+------------+----------+\n",
      "|Adults (25-64)      |121620      |70.60     |\n",
      "|Young Adults (18-24)|33741       |19.59     |\n",
      "|Children (<18)      |10899       |6.33      |\n",
      "|Elderly (>64)       |6011        |3.49      |\n",
      "+--------------------+------------+----------+\n",
      "\n",
      "Execution time with UDF: 0.72 seconds\n",
      "\n",
      "Step 5 completed (DataFrame API WITH UDF)."
     ]
    }
   ],
   "source": [
    "# Step 5: DataFrame API WITH UDF (FIXED)\n",
    "\n",
    "from pyspark.sql.functions import udf, col, desc\n",
    "from pyspark.sql.types import StringType\n",
    "import time\n",
    "\n",
    "print(\"Step 5: DataFrame API WITH UDF\")\n",
    "print(\"Starting execution time measurement...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the UDF function\n",
    "def categorize_age_udf(age):\n",
    "    \"\"\"User Defined Function to categorize age into groups\"\"\"\n",
    "    try:\n",
    "        age_int = int(age)\n",
    "        if age_int < 18:\n",
    "            return \"Children (<18)\"\n",
    "        elif 18 <= age_int <= 24:\n",
    "            return \"Young Adults (18-24)\"\n",
    "        elif 25 <= age_int <= 64:\n",
    "            return \"Adults (25-64)\"\n",
    "        elif age_int > 64:\n",
    "            return \"Elderly (>64)\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Register the UDF\n",
    "age_group_udf = udf(categorize_age_udf, StringType())\n",
    "# Apply UDF to create age groups\n",
    "df_with_udf = df_agg_clean.withColumn(\n",
    "    \"Age_Group_UDF\",\n",
    "    age_group_udf(col(\"Vict_Age_Int\"))\n",
    ")\n",
    "\n",
    "# Need to import count function again\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Group and count\n",
    "df_udf_counts = df_with_udf.groupBy(\"Age_Group_UDF\") \\\n",
    "    .agg(count(\"*\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\"))\n",
    "\n",
    "# Calculate percentages\n",
    "total_udf = df_with_udf.count()\n",
    "df_udf_final = df_udf_counts.withColumn(\n",
    "    \"Percentage\",\n",
    "    (col(\"Victim_Count\") / total_udf * 100).cast(\"decimal(5,2)\")\n",
    ")\n",
    "\n",
    "# Measure execution time\n",
    "execution_time_udf = time.time() - start_time\n",
    "\n",
    "print(f\"\\nUDF Results:\")\n",
    "df_udf_final.show(truncate=False)\n",
    "print(f\"Execution time with UDF: {execution_time_udf:.2f} seconds\")\n",
    "\n",
    "print(\"\\nStep 5 completed (DataFrame API WITH UDF).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf25c4d-fb34-4fbe-9f6d-147062cb9ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fb677cc53f47f1b3441dc1c4d8168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: RDD API Implementation\n",
      "Starting execution time measurement...\n",
      "RDD partition count: 8\n",
      "RDD element count: 172271\n",
      "\n",
      "RDD API Results:\n",
      "+--------------------+------------+----------+\n",
      "|Age_Group           |Victim_Count|Percentage|\n",
      "+--------------------+------------+----------+\n",
      "|Adults (25-64)      |121620      |70.6      |\n",
      "|Young Adults (18-24)|33741       |19.59     |\n",
      "|Children (<18)      |10899       |6.33      |\n",
      "|Elderly (>64)       |6011        |3.49      |\n",
      "+--------------------+------------+----------+\n",
      "\n",
      "Execution time with RDD API: 11.87 seconds\n",
      "\n",
      "Step 6 completed (RDD API)."
     ]
    }
   ],
   "source": [
    "# Step 6: RDD API Implementation\n",
    "\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "\n",
    "print(\"Step 6: RDD API Implementation\")\n",
    "print(\"Starting execution time measurement...\")\n",
    "\n",
    "rdd_start_time = time.time()\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "crime_rdd = df_agg_clean.rdd\n",
    "\n",
    "print(f\"RDD partition count: {crime_rdd.getNumPartitions()}\")\n",
    "print(f\"RDD element count: {crime_rdd.count()}\")\n",
    "\n",
    "# Define mapping function\n",
    "def map_to_age_group(row):\n",
    "    \"\"\"Map each row to (age_group, 1)\"\"\"\n",
    "    age = row.Vict_Age_Int\n",
    "    \n",
    "    if age < 18:\n",
    "        return (\"Children (<18)\", 1)\n",
    "    elif 18 <= age <= 24:\n",
    "        return (\"Young Adults (18-24)\", 1)\n",
    "    elif 25 <= age <= 64:\n",
    "        return (\"Adults (25-64)\", 1)\n",
    "    elif age > 64:\n",
    "        return (\"Elderly (>64)\", 1)\n",
    "    else:\n",
    "        return (\"Unknown\", 1)\n",
    "\n",
    "# MapReduce operation\n",
    "age_group_rdd = crime_rdd.map(map_to_age_group)\n",
    "\n",
    "# Reduce by key (sum counts for each age group)\n",
    "reduced_rdd = age_group_rdd.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sort by count in descending order\n",
    "sorted_rdd = reduced_rdd.map(lambda x: (x[1], x[0])) \\\n",
    "                       .sortByKey(ascending=False) \\\n",
    "                       .map(lambda x: (x[1], x[0]))\n",
    "\n",
    "# Collect results\n",
    "rdd_results = sorted_rdd.collect()\n",
    "\n",
    "# Calculate total for percentages\n",
    "total_rdd = sum(count for _, count in rdd_results)\n",
    "\n",
    "# Convert to list of Rows for DataFrame creation\n",
    "result_rows = []\n",
    "for age_group, count in rdd_results:\n",
    "    percentage = (count / total_rdd * 100) if total_rdd > 0 else 0\n",
    "    result_rows.append(Row(\n",
    "        Age_Group=age_group,\n",
    "        Victim_Count=count,\n",
    "        Percentage=round(percentage, 2)\n",
    "    ))\n",
    "\n",
    "# Create DataFrame from RDD results\n",
    "df_rdd_results = spark.createDataFrame(result_rows)\n",
    "\n",
    "rdd_execution_time = time.time() - rdd_start_time\n",
    "print(f\"\\nRDD API Results:\")\n",
    "df_rdd_results.show(truncate=False)\n",
    "print(f\"Execution time with RDD API: {rdd_execution_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nStep 6 completed (RDD API).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567a15b-17f8-4c3d-8953-431a1dd2916b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
